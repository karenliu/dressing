\section{Dressing Control}

Our system allows a user to decompose the whole dressing sequence into multiple segments and specify high level actions for each segment (Table \ref{table:actionQueue}). We designed a small set of actions that are tailored for dressing control. The most important actions are alignment, traversal and tracking. 

\subsection{Alignment}
The first step to put on a cloth is to align one end effector with a cloth feature. For example, to align one hand with the armhole, or one foot with the belt loop. In alignment, we often choose a loop of vertices as the cloth feature and the goal is to control the end effector to pass through this loop. However, the target cloth feature is often folded and occluded by other parts of the cloth. It is not directly visable or reachable from the current end effector location. Furthermore, the alignment is a process of chasing a moving feature which has nonlinear dynamics and complex deformations. It is difficult to predict the movement of the feature and plan ahead. Even worse, as the end effector approaches the feature, it is highly likely that it will bump into the nearby cloth and knock the target away.  To address these challenges, we design a feedback controller for the alignment action.

\karen{Can we have an Algorithm (pseudo code) to summarize the following two paragraphs?}
Our alignment controller first finds an intermediate goal towards the target feature, and then move the end effector a small distance towards this goal in a way that minimizes the chance to knock away the target feature. These two steps are performed iteratively until the end effector successfully reaches the feature.

We set the intermediate goal as a vertex on the cloth which is visible from the end effector and it has the smallest geodesic distance to the target feature (Figure \ref{fig:geodesic}). However, the cloth geometry is represented as a single-layer triangular mesh, which means no difference between a point at the outer and the inner surface of the cloth. Since the end effector needs to reach the target feature from inside the cloth, we duplicate the mesh into two layers. These two layers are connected at their boundary. We precompute the geodesic distance on the two-layer cloth mesh using breadth first traversal starting from the feature vertices at the inner layer. At runtime, we find the unoccluded vertex with the minimal geodesic distance using rasterization techniques. We place a camera at the end effector and render the geodesic distance on the cloth mesh into a cubic environmental map. The brightest pixel on the map corresponds the direction to the intermediate goal. Note that we choose to render all six directions of the cubic map, which not only allows the end effector to move forward, but also sideways and backtrack. We find that the ability to detect the intermediate goal behind the end effector drastically increases the success rate of the alignment.

Given the intermediat goal $\vc{p}_g$ and the current end effector location $\vc{p}^n$, we set the desired end effector location $\hat{\vc{p}}$ at the next time step to be 
\begin{equation}
  \hat{\vc{p}} = \vc{p}^n+\alpha(\vc{p}_g - \vc{p}^n)
  \label{eq:target}
\end{equation}
where $\alpha$ is the step size that is specified by the user.

We found that in addition to the end effector location, its orientation also plays an important role in the alignment action. Since the end effector needs to navigate through a tight and winding space between folds of the cloth, its orientation should be aligned with the moving direction. This way of moving reduces the space swept by the end effector, lowers its chance to collide with nearby cloth and minimizes the normal impacts if collisions happen. For this reason, we add the following objective to the optimization (Equation~\ref{eq:IK}).

\begin{displaymath}
E_{orientation} = 1-\frac{(\vc{p}_g-\vc{p}^n)^T}{||\vc{p}_g-\vc{p}^n||_2}\vc{d(q})
\end{displaymath}
where $\vc{d(q)}$ is the direction from the center to the tip of the end effector.

In addition, we also limit the joint speed within a certain threshold to ensure the smoothness of the motion.
\begin{displaymath}
-\dot{\vc{q}}_{thresh} \leq \frac{\vc{q} - \vc{q}^n}{\Delta t} \leq \dot{\vc{q}}_{thresh}
\end{displaymath}
where $\vc{q}^n$ is the current pose, $\Delta t$ is the time step, and $\dot{\vc{q}}_{thresh}$ is the maximum allowed speed.

To determine whether the alignment action has succeeded, we first find a plane that best fits the cloth feature.We then project the center of the end effector and the vertex loop of the feature onto this plane. If the center of the end effector has passed over this plane and the projected center is within the projected feature loop, the alignment has succeeded and we move on to the next action in the queue.

\subsection{Traversal}
After alignment, the center of the end effector has passed the desired cloth feature. However, at this point, the feature can still easily fall out of control due to gravity or inappropriate end effector motions. We design a traversal action to secure the alignment, which enables the end effector to pass throught the opening entirely and further into the cloth tubes. Examples of traversal include stretching an arm into a sleeve and dragging the pants up to the waist. To accomplish this action, we first compute a series of desired poses of the end effector or the whole limb. We then solve the collision-free IK for their corresponding full body poses, which are used as keyframes of the entire traversal motion. Although these keyframes are free of self collision among body parts, directly interpolating them can lead to inter-body penetrations. For this reason, we apply bi-directional Rapidly Expanding Random Tree (RRT) \cite{} to find a collision free trajectory between adjacent keyframes.

We observed that in daily dressing activities, the traversal action can be categorized into two types. In the first type, the limb to be dressed remains relatively motionless while another limb \emph{drags} the cloth along it. For example, the character uses its hands to drag the pants up along the legs. In the second type, the limb \emph{stretches} itself to pass through the tubular part of the cloth without assistance from other limbs. This situation is often seen when putting on the second sleeve of a jacket. To accomodate both types of travesal, we designed different desired poses of the end effector or the limb.

\paragraph{Dragging.} In the first case, a user can specify one end effector to drag the cloth and a set of body parts $\{B_1 ,..., B_n\}$ that the cloth should be dragged upon. We use the positions of the parent joints of those bodies as path nodes. For example, if the character is using his right hand to dress the left arm, the path nodes are the left wrist, the left elbow and the left shoulder (Figure \ref{}). For each of the path node $\vc{p}_i$, we set the target end effector location $\hat{\vc{p}}=\vc{p}_i$ in Equation~\ref{eq:IK}, and solve the collision-free IK for one keyframe of the dragging motion. 

\paragraph{Stretching.} In the second case of traversal, one limb straightens into the cloth tube without assistance from other end effectors. While the limb is stretching, another body part needs to keep the cloth from moving with the limb. We call this body part a \emph{fixture node}. For example, when stretching an arm into a sleeve as shown in Figure \ref{}, the fixture node is the opposite shoulder. We implemented the fixture node as an additional constraint in the optimization (Equation~\ref{eq:IK}).

\begin{align}
  \label{eq:fixtureNode}
  \vc{R}(\vc{q})& = \vc{R}^n\\
  \nonumber  \vc{t}(\vc{q})& = \vc{t}^n
\end{align}
where $\vc{R}^n$ and $\vc{t}^n$ are the current rotation and translation of the fixture node.

Besides the fixture node, a correct stretching direction is also critical to a successful stretching action. We used the direction from the center of the fixture node to the current end effector location as the stretching direction. Along this direction, the friction force caused by the stretching limb is canceled by the cloth tension pulled from the fixture node. This prevents the cloth feature from moving with the end effector so that the limb can further pass through the feature. We add an objective term to Equation \ref{eq:IK} to specify the desired stretching direction.
\begin{equation}
  E_{stretch} = 1 - \hat{\vc{d}}^T\vc{d(q)}
  \label{eq:stretching}
\end{equation}
where $\hat{\vc{d}}$ is the desired stretching direction and $\vc{d(q)}$ is the direction from the root to the tip of the limb.

We solve the collision-free IK with the additional objective (Equation~\ref{eq:stretching}) and constraint (Equation~\ref{eq:fixtureNode}), which gives us a key frame of full body pose for the stretching motion.


\subsection{Tracking}

To preserve the dressing style specified by the user, We use the tracking action to follow the reference motion $\hat{\vc{q}}(t)$. In most cases, it simply uses the next pose in the reference.
\begin{displaymath}
\vc{q} = \hat{\vc{q}}^{n+1}
\end{displaymath}
However, after alignment and traversal, the joint trajectory of the character could deviate far from the reference motion. Interpolation from the current pose to a pose in the reference is necessary for a smooth animation. To prevent inter-body collisions during the interpolation, similar to the dragging controller, we apply RRT \cite{} to find a collision free path and then follow this path to the target pose.

\subsection{Other Actions}

\paragraph{Grip and release.}
The grip action models the grasping of the character's hand. The cloth feature moves together with the character's hand if it is gripped. This action constrains the vertices in the cloth feature to the local frame of the end effector.
\begin{displaymath}
\vc{p}_w = \vc{Rp} + \vc{t}
\end{displaymath}
where $\vc{p}_w$ is the world coordinate of a vertex in the cloth feature, $\vc{p}$ is the local coordinate of this vertex at the end effector's frame, $\vc{R}$ and $\vc{t}$ are the rotation and translation of the end effector. The release action simply removes the above constraints and the cloth feature no longer moves with the end effector once it is released.

\paragraph{Idling.} This action freezes the character's motion for a user-specified time period. The main purpose of this action is to wait the clothes to settle before proceeding to the next dressing action.

