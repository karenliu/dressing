\section{Dressing Control}

We decompose the whole dressing sequence into multiple stages and speicify high level actions for each stage. Table~\ref{Table:ActionQueue} exemplify the actions to dress the upper body of a character. The three core actions are aligning, traversal and tracking.

\begin{table}
  \centering
  \begin{tabular}{|l|l|}
    \hline
    Action & Description \\
    \hline
    Grip(RH, $\vc{f}_{1}$) & Grip the colar feature $\vc{f_1}$  with the right hand.\\
    Track($\hat{\vc{q}}$, $T_1$) & Track the reference motion $\hat{\vc{q}}$ for $T_1$ seconds.\\
    Align(LH, $\vc{f}_{2}$) & Align the left hand with the left armhole $\vc{f}_2$.\\
    Drag(RH, ${\vc\{p}_i\}$) & Drag the cloth from the wrist $\vc{p}_1$ to the elbow\\
    &                          $\vc{p}_2$ to the shoulder $\vc{p}_3$.\\
    Release(RH) & Release the cloth from the right hand.\\
    Idle($T_2$) & Idle for $T_2$ seconds.\\
    Track($\hat{\vc{q}}$, $T_3$) & Track the reference motion $\hat{\vc{q}}$ for $T_3$ seconds.\\
    Align(RH, $\vc{f}_{3}$) & Align the right hand with the right armhole $\vc{f}_3$.\\
    Stretch(RH) & Stretching the right hand into the right sleeve.\\
    Track($\hat{\vc{q}}$, $T_4$) & Track the reference motion $\hat{\vc{q}}$ for $T_4$ seconds. \\
    Idle($T_5$) & Idle for $T_5$ seconds until the cloth is settled.\\
    \hline
  \end{tabular}
  \caption{An example action queue for dressing the upper body of a character with a jacket.}
\end{table}


\subsection{Alignment}
The first important step to put on a cloth is to align one end effector with a cloth feature. For example, aligning a hand with an armhole, or a foot with the belt loop. In alignment, a feature is usually a loop of vertices. Alignment is challenging for two reasons. First, the target cloth feature is often folded and occluded by other parts of the cloth. It is not directly visable or reachable from the end effector location. Second, the alignment process is to chase a moving feature which has nonlinear dynamics and complex deformations. As the end effector approaches the feature, it will inevitably bumped into the nearby cloth, which could knock away the target.  To address these two challenges, we design a feedback controller for the alignment action.

Our alignment controller proceeds the following two steps iteratively until the end effector is inside the garment feature. In the first step, our system finds an intermediate goal towards the target feature and in the second step, the end effector is moved a small distance towards this goal in a way that minimizes the chance to knock away the target feature.

We set the intermediate goal as a vertex on the cloth which is visible from the end effector and it has the smallest geodesic distance to the target feature. However, since the cloth geometry is represented as a single-layer triangular mesh, a point outside the cloth surface has the same distance as a point at the same location but inside the surface. To prevent the end effector from approaching the feature from the wrong side, we duplicate the cloth mesh into two layers.  We precompute the geodesic distance on the cloth mesh using breadth first traversal starting from the feature vertices at the inner layer. At run time, we find the unoccluded vertex with the minimal geodesic distance using rasterization techniques. We place a camera at the end effector and render the geodesic distance on the  cloth mesh into a cubic environmental map. The direction towards the intermediate goal corresponds to the brightest pixel in the environmental map. Note that we choose to render all six directions of the cubic map, which not only allows the end effector to move forward, but also sideway and backtrack. We find that the ability to detect intermediate goal behind the end effector drastically increase the success rate of the alignment.

Given the intermediat goal $\vc{p}_g$ and the current end effector location $\vc{p}^n$, we first set the target end effector location $\hat{\vc{p}}$ at the next time step to be 
\begin{equation}
  \hat{\vc{p}} = \vc{p}^n+\alpha(\vc{p}_g - \vc{p}^n)
  \label{eq:target}
\end{equation}
where $\alpha$ is the step size that is specified by the user.

In addition to the collision-free IK (Equation \ref{eq:IK} and \ref{eq:collision}) with target end effector location (Equation \ref{eq:target}), we include an addition objective and one more constraint.

The additional objective $E_{orientation}$ helps the end effector navigate through the tight and winding space between folds of the cloth with minimal normal impacts to the cloth. It aligns the orientation of the end effector with its moving direction.
\begin{displaymath}
E_{orientation} = 1-\frac{(\vc{p}_g-\vc{p}^n)^T}{||\vc{p}_g-\vc{p}^n||_2}\vc{d(q})
\end{displaymath}
where $\vc{d(q)}$ is the direction from the center to the tip of the end effector.

We also limit the joint speed within a threshold $\dot{\vc{q}}_{lim}$ to ensure the smoothness of the motion.
\begin{displaymath}
-\dot{\vc{q}}_{lim} \leq \frac{\vc{q} - \vc{q}^n}{\Delta t} \leq \dot{\vc{q}}_{lim}
\end{displaymath}
where $\vc{q}^n$ is the current pose.

The alignment action ends when the center of the end effector is within the feature loop and has passed through the plane that best fits the feature.

\subsection{Traversal}
After alignment, the end effector is halfway through the desired opening of the cloth. However, this configuration is not secure. The feature can easily fall out of control due to gravity or inappropriate end effector motion. For this reason, we design a traversal action before interpolating back to the reference motion.

The traversal action enable a limb to pass through the corresponding tube-shaped part of the cloth. For example, stretching an arm into a sleeve. We observed that in daily dressing activities, there are two types of traversal action. In the first type, one end effector assists another by \emph{dragging} the cloth along the limb to be dressed. One example is to lift the pants from the foot to the waist. In the second type, the limb \emph{stretches} streches to pass through the tube without assistance from other end effectors. This situation is commonly seen when dressing the second sleeve of a jacket from the back.

\paragraph{Dragging.} We design a dragging controller to handle the first case. Its input includes the assisting end effector and a set of path nodes $\{\vc{p}_1 ,..., \vc{p}_n\}$ that the cloth should be dragged through. In our system, we use the positions of the joints of the assisted limb as the path nodes. For example, if the character is using his left arm to help dressing the right arm. The path nodes are the positions of the right wrist, the right elbow and the right shoulder. For each of the path node $\vc{p}_i$, We set the target end effector location $\hat{\vc{p}}=\vc{p}_i$ in Equation~\ref{eq:endEffectorConstraint} and solve the collision-free IK for a full body pose. We compute $n$ poses from all the path nodes and use them as keyframes. Directly interpolating between the keyframes can cause collisions between different body parts. For this reason, we apply bi-directional Rapidly Expanding Random Tree (RRT) \cite{} to find a collision free joint trajectory between adjacent keyframes and follow this trajectory to drag the cloth through all the desired path nodes.

\paragraph{Stretching.} The key of a successful stretching motion is to find the direction of stretching and the orientation of the end effector.


\subsection{Tracking}

To preserve the dressing style specified by the user, We use the tracking action to follow the reference motion $\hat{\vc{q}}$. In most cases, it simply uses the next pose in the reference motion.
\begin{displaymath}
\vc{q} = \hat{\vc{q}}^{n+1}
\end{displaymath}
However, after alignment and traversal, the joint trajectory of the character could deviate a lot from the reference motion. Interpolation from the current pose to a pose in the reference motion is necessary to generate a smooth animation. To prevent collisions among different body parts during the interpolation, similar to the dragging controller, we apply RRT \cite{} to find a collision free path and then follow this path to the target pose.


\subsection{Miscs}

\paragraph{Grip and release.}
The grip action models the grasping of a human's hand. It takes an end effector name and a cloth feature as parameters. This action establishes equality constraints between the set of vertices in the cloth feature to the coordinate frame of the end effector.
\begin{displaymath}
\vc{p}_w = \vc{Rp} + \vc{t}
\end{displaymath}
where $\vc{p}_w$ is the world coordinate of a vertex in the cloth feature, $\vc{p}$ is the local coordinate of this vertex at the end effector's frame, $\vc{R}$ and $\vc{t}$ are the rotation and translation of the end effector. After being gripped, the cloth feature will move together with the character's hand. The release action simply removes the above constraints. The cloth feature will no long move with the end effector once it is released.

\paragraph{Idling.} The purpose of idling is to wait the clothes to settle before proceeding to the next dressing stage. During idling, the character keeps current pose for a period $T$ that is specified by the user.

